{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 1: Cài đặt các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install split-folders\n",
    "!pip install albumentations\n",
    "!pip install tqdm\n",
    "!pip install opencv-python-headless\n",
    "!pip install torch torchvision torchaudio\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import datetime\n",
    "import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 2: Đặt đường dẫn home chứa folder project hiện tại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "if platform.system() == 'Linux':\n",
    "    home_dir = '/content/drive/MyDrive/ClassificationofMangoDiseases'\n",
    "elif platform.system() == 'Windows':\n",
    "    home_dir = 'D:\\Projects\\ClassificationofMangoDiseases'\n",
    "else:\n",
    "    raise ValueError('Unsupported platform')\n",
    "\n",
    "print(f'Home directory: {home_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 3: Kết nối với Google Drive nếu đang chạy trên Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Linux':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 4: Đặt đường dẫn tới tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đường dẫn tới tập dữ liệu đã chọn (gốc hoặc đã remove background)\n",
    "data_dir = os.path.join(home_dir, 'data/MangoFruitDDS/SenMangoFruitDDS_bgremoved')  # Hoặc 'SenMangoFruitDDS_original'\n",
    "output_dir = os.path.join(home_dir, 'data/processed')\n",
    "\n",
    "print(f'Data directory: {data_dir}')\n",
    "print(f'Output directory: {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 5: Tiền xử lý dữ liệu và phân chia tập dữ liệu\n",
    "\n",
    "Sử dụng thư viện `split-folders` để phân chia tập dữ liệu thành các tập `train`, `valid`, và `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa thư mục đầu ra nếu đã tồn tại\n",
    "if os.path.exists(output_dir):\n",
    "    import shutil\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "# Phân chia dữ liệu\n",
    "splitfolders.ratio(data_dir, output=output_dir, seed=42, ratio=(.7, .2, .1), group_prefix=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 6: Hiển thị thông tin thư mục sau khi phân chia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra các thư mục sau khi phân chia\n",
    "for root, dirs, files in os.walk(output_dir):\n",
    "    level = root.replace(output_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * (level)\n",
    "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "    subindent = ' ' * 4 * (level + 1)\n",
    "    for f in files:\n",
    "        print('{}{}'.format(subindent, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 7: Xác nhận kết quả\n",
    "\n",
    "Kiểm tra lại thư mục đã được phân chia đúng cách."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Hiển thị một số hình ảnh từ tập train\n",
    "train_dir = os.path.join(output_dir, 'train')\n",
    "class_names = os.listdir(train_dir)\n",
    "print(f'Classes: {class_names}')\n",
    "\n",
    "# Chọn ngẫu nhiên một lớp\n",
    "random_class = random.choice(class_names)\n",
    "print(f'Random class: {random_class}')\n",
    "\n",
    "# Chọn ngẫu nhiên một hình ảnh từ lớp đó\n",
    "random_image_path = os.path.join(train_dir, random_class, random.choice(os.listdir(os.path.join(train_dir, random_class))))\n",
    "print(f'Random image path: {random_image_path}')\n",
    "\n",
    "# Hiển thị hình ảnh\n",
    "image = Image.open(random_image_path)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 8: Thực hiện tăng cường dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "# Định nghĩa các phép tăng cường dữ liệu\n",
    "augmentations = A.Compose([\n",
    "    A.RandomRotate90(),\n",
    "    A.Flip(),\n",
    "    A.Transpose(),\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(),\n",
    "        A.MultiplicativeNoise()\n",
    "    ], p=0.2),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(p=0.2),\n",
    "        A.MedianBlur(blur_limit=3, p=0.1),\n",
    "        A.Blur(blur_limit=3, p=0.1),\n",
    "    ], p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=20, p=0.2),\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(p=0.3),\n",
    "        A.GridDistortion(p=0.1),\n",
    "        A.PiecewiseAffine(p=0.3),\n",
    "    ], p=0.2),\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit=2),\n",
    "        A.Sharpen(),\n",
    "        A.Emboss(),\n",
    "        A.RandomBrightnessContrast(),\n",
    "    ], p=0.3),\n",
    "    A.HueSaturationValue(p=0.3),\n",
    "])\n",
    "\n",
    "# Tạo thư mục đầu ra cho dữ liệu tăng cường\n",
    "augmented_dir = os.path.join(home_dir, 'data/augmented')\n",
    "if not os.path.exists(augmented_dir):\n",
    "    os.makedirs(augmented_dir)\n",
    "\n",
    "# Áp dụng tăng cường dữ liệu\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(train_dir, class_name)\n",
    "    augmented_class_dir = os.path.join(augmented_dir, class_name)\n",
    "    if not os.path.exists(augmented_class_dir):\n",
    "        os.makedirs(augmented_class_dir)\n",
    "    for img_name in tqdm(os.listdir(class_dir)):\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        augmented = augmentations(image=image)\n",
    "        augmented_image = augmented['image']\n",
    "        augmented_image = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
    "        augmented_img_name = f'aug_{img_name}'\n",
    "        cv2.imwrite(os.path.join(augmented_class_dir, augmented_img_name), augmented_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 9: Xây dựng các mô hình và huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Define common hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Define common loss function and optimizer\n",
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Define image size and input shape\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "input_shape = (img_height, img_width, 3)\n",
    "\n",
    "# Function to create a simple CNN model\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Function to create a ResNet model\n",
    "def create_resnet_model(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Function to create an Inception model\n",
    "def create_inception_model(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.InceptionV3(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Function to create a DenseNet model\n",
    "def create_densenet_model(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.DenseNet121(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Function to create a model using Transfer Learning\n",
    "def create_transfer_learning_model(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.VGG16(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "num_classes = len(class_names)  # Adjust this according to your dataset\n",
    "cnn_model = create_cnn_model(input_shape, num_classes)\n",
    "resnet_model = create_resnet_model(input_shape, num_classes)\n",
    "inception_model = create_inception_model(input_shape, num_classes)\n",
    "densenet_model = create_densenet_model(input_shape, num_classes)\n",
    "transfer_learning_model = create_transfer_learning_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the models\n",
    "models = [cnn_model, resnet_model, inception_model, densenet_model, transfer_learning_model]\n",
    "for model in models:\n",
    "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 10: Huấn luyện và lưu mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "date_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "def get_model_save_path(model_name, augmented=False):\n",
    "    suffix = 'Aug' if augmented else 'Ori'\n",
    "    model_name_with_suffix = f\"{model_name}{suffix}\"\n",
    "    \n",
    "    if platform.system() == 'Linux':\n",
    "        base_path = f'/content/drive/MyDrive/ClassificationofMangoDiseases/models/{model_name_with_suffix}/{date_time}'\n",
    "    elif platform.system() == 'Windows':\n",
    "        base_path = f'D:\\\\Projects\\\\ClassificationofMangoDiseases\\\\models\\\\{model_name_with_suffix}\\\\{date_time}'\n",
    "    else:\n",
    "        raise ValueError('Unsupported platform')\n",
    "    \n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "    \n",
    "    return base_path\n",
    "\n",
    "def create_optimizer():\n",
    "    return tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "def plot_history(history, base_path):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig(os.path.join(base_path, 'accuracy.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig(os.path.join(base_path, 'loss.png'))\n",
    "    plt.close()\n",
    "\n",
    "def save_classification_report(y_true, y_pred, class_names, results_path):\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df.to_csv(os.path.join(results_path, 'classification_report.csv'), index=True)\n",
    "\n",
    "def save_confusion_matrix(y_true, y_pred, class_names, results_path):\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(os.path.join(results_path, 'confusion_matrix.png'))\n",
    "    plt.close()\n",
    "\n",
    "def save_roc_curve(y_true, y_score, results_path, num_classes):\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    # Binarize the output\n",
    "    y_true_binarized = label_binarize(y_true, classes=[i for i in range(num_classes)])\n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot ROC curve for each class\n",
    "    plt.figure()\n",
    "    for i in range(num_classes):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, label='Class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(results_path, 'roc_curve.png'))\n",
    "    plt.close()\n",
    "\n",
    "def save_precision_recall_curve(y_true, y_score, results_path, num_classes):\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    y_true_binarized = label_binarize(y_true, classes=[i for i in range(num_classes)])\n",
    "    \n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    for i in range(num_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_true_binarized[:, i], y_score[:, i])\n",
    "\n",
    "    # Plot Precision-Recall curve for each class\n",
    "    plt.figure()\n",
    "    for i in range(num_classes):\n",
    "        plt.plot(recall[i], precision[i], lw=2, label='Class {0}'.format(i))\n",
    "    \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(results_path, 'precision_recall_curve.png'))\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_model(model, valid_generator, class_names, base_path, results_path):\n",
    "    y_true = valid_generator.classes\n",
    "    y_pred = model.predict(valid_generator)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    save_classification_report(y_true, y_pred_classes, class_names, results_path)\n",
    "    save_confusion_matrix(y_true, y_pred_classes, class_names, results_path)\n",
    "    save_roc_curve(y_true, y_pred, results_path, num_classes=len(class_names))\n",
    "    save_precision_recall_curve(y_true, y_pred, results_path, num_classes=len(class_names))\n",
    "\n",
    "# Training data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'train'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'val'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "original_models = {\n",
    "    'CNNCustomOri': cnn_model,\n",
    "    'ResNet50Ori': resnet_model,\n",
    "    'InceptionV3Ori': inception_model,\n",
    "    'DenseNet121Ori': densenet_model,\n",
    "    'VGG16Ori': transfer_learning_model\n",
    "}\n",
    "\n",
    "# Evaluate on original and augmented datasets\n",
    "def train_and_evaluate(models, train_generator, valid_generator, class_names, augmented=False):\n",
    "    for model_name, model in models.items():\n",
    "        model.compile(optimizer=create_optimizer(), loss=loss_function, metrics=['accuracy'])\n",
    "        base_path = get_model_save_path(model_name, augmented)\n",
    "        history = model.fit(train_generator, validation_data=valid_generator, epochs=epochs)\n",
    "        model.save(os.path.join(base_path, 'model.h5'))\n",
    "        plot_history(history, base_path)\n",
    "        \n",
    "        # Evaluate on test sets\n",
    "        results1_path = os.path.join(base_path, 'results1')\n",
    "        results2_path = os.path.join(base_path, 'results2')\n",
    "        evaluate_model(model, valid_generator, class_names, base_path, results1_path)\n",
    "        evaluate_model(model, valid_generator, class_names, base_path, results2_path)\n",
    "\n",
    "# Train and evaluate on original dataset\n",
    "train_and_evaluate(original_models, train_generator, valid_generator, class_names, augmented=False)\n",
    "\n",
    "# Augmented training data\n",
    "augmented_train_dir = os.path.join(home_dir, 'data/augmented')\n",
    "train_generator_aug = train_datagen.flow_from_directory(\n",
    "    augmented_train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "augmented_models = {\n",
    "    'CNNCustomAug': create_cnn_model(input_shape, num_classes),\n",
    "    'ResNet50Aug': create_resnet_model(input_shape, num_classes),\n",
    "    'InceptionV3Aug': create_inception_model(input_shape, num_classes),\n",
    "    'DenseNet121Aug': create_densenet_model(input_shape, num_classes),\n",
    "    'VGG16Aug': create_transfer_learning_model(input_shape, num_classes)\n",
    "}\n",
    "\n",
    "# Train and evaluate on augmented dataset\n",
    "train_and_evaluate(augmented_models, train_generator_aug, valid_generator, class_names, augmented=True)\n",
    "\n",
    "# Evaluate on 'data/MangoFruitDDS/SenMangoFruitDDS_original'\n",
    "original_data_dir = os.path.join(home_dir, 'data/MangoFruitDDS/SenMangoFruitDDS_original')\n",
    "original_train_generator = train_datagen.flow_from_directory(\n",
    "    original_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Train and evaluate on original dataset without augmentation\n",
    "train_and_evaluate(original_models, original_train_generator, valid_generator, class_names, augmented=False)\n",
    "\n",
    "# Train and evaluate on augmented dataset without augmentation\n",
    "train_and_evaluate(augmented_models, original_train_generator, valid_generator, class_names, augmented=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
