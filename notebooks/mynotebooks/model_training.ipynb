{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 1: Cài đặt các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (2.16.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.2 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\minh dua\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\minh dua\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorflow-intel==2.16.2->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.2->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.2->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.2->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\minh dua\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.2->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: split-folders in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\minh dua\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\minh dua\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\minh dua\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: albumentations in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (1.4.11)\n",
      "Requirement already satisfied: numpy>=1.24.4 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from albumentations) (1.14.0)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from albumentations) (0.24.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from albumentations) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from albumentations) (4.12.2)\n",
      "Requirement already satisfied: scikit-learn>=1.3.2 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from albumentations) (1.5.1)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from albumentations) (2.8.2)\n",
      "Requirement already satisfied: albucore>=0.0.11 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from albumentations) (0.0.12)\n",
      "Requirement already satisfied: eval-type-backport in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from albumentations) (0.2.0)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from albumentations) (4.10.0.84)\n",
      "Requirement already satisfied: tomli>=2.0.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from albucore>=0.0.11->albumentations) (2.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (2.20.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (10.4.0)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (2.34.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (2024.7.2)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\minh dua\\appdata\\roaming\\python\\python310\\site-packages (from scikit-image>=0.21.0->albumentations) (24.0)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from scikit-learn>=1.3.2->albumentations) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from scikit-learn>=1.3.2->albumentations) (3.5.0)\n",
      "Requirement already satisfied: torch in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from opencv-python-headless) (1.26.4)\n",
      "Requirement already satisfied: seaborn in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from seaborn) (3.9.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\minh dua\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\minh dua\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\minh dua\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\minh dua\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\minh dua\\.conda\\envs\\mangoddsenv\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\minh dua\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install split-folders\n",
    "!pip install matplotlib\n",
    "!pip install albumentations\n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install opencv-python-headless\n",
    "!pip install seaborn\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import datetime\n",
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import splitfolders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 2: Đặt đường dẫn home chứa folder project hiện tại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home directory: D:\\Projects\\ClassificationofMangoDiseases\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "if platform.system() == 'Linux':\n",
    "    home_dir = '/content/drive/MyDrive/ClassificationofMangoDiseases'\n",
    "elif platform.system() == 'Windows':\n",
    "    home_dir = 'D:\\Projects\\ClassificationofMangoDiseases'\n",
    "else:\n",
    "    raise ValueError('Unsupported platform')\n",
    "\n",
    "print(f'Home directory: {home_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 3: Kết nối với Google Drive nếu đang chạy trên Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if platform.system() == 'Linux':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 4: Đặt đường dẫn tới tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: D:\\Projects\\ClassificationofMangoDiseases\\data/MangoFruitDDS/SenMangoFruitDDS_bgremoved\n",
      "Output directory: D:\\Projects\\ClassificationofMangoDiseases\\data/processed\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn tới tập dữ liệu đã chọn (gốc hoặc đã remove background)\n",
    "data_dir = os.path.join(home_dir, 'data/MangoFruitDDS/SenMangoFruitDDS_bgremoved')  # Hoặc 'SenMangoFruitDDS_original'\n",
    "output_dir = os.path.join(home_dir, 'data/processed')\n",
    "\n",
    "print(f'Data directory: {data_dir}')\n",
    "print(f'Output directory: {output_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 5: Tiền xử lý dữ liệu và phân chia tập dữ liệu\n",
    "\n",
    "Sử dụng thư viện `split-folders` để phân chia tập dữ liệu thành các tập `train`, `valid`, và `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'splitfolders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(output_dir)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Phân chia dữ liệu\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43msplitfolders\u001b[49m\u001b[38;5;241m.\u001b[39mratio(data_dir, output\u001b[38;5;241m=\u001b[39moutput_dir, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, ratio\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m.7\u001b[39m, \u001b[38;5;241m.2\u001b[39m, \u001b[38;5;241m.1\u001b[39m), group_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'splitfolders' is not defined"
     ]
    }
   ],
   "source": [
    "# Xóa thư mục đầu ra nếu đã tồn tại\n",
    "if os.path.exists(output_dir):\n",
    "    import shutil\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "# Phân chia dữ liệu\n",
    "splitfolders.ratio(data_dir, output=output_dir, seed=42, ratio=(.7, .2, .1), group_prefix=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 6: Hiển thị thông tin thư mục sau khi phân chia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kiểm tra các thư mục sau khi phân chia\n",
    "for root, dirs, files in os.walk(output_dir):\n",
    "    level = root.replace(output_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * (level)\n",
    "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "    subindent = ' ' * 4 * (level + 1)\n",
    "    for f in files:\n",
    "        print('{}{}'.format(subindent, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 7: Xác nhận kết quả\n",
    "\n",
    "Kiểm tra lại thư mục đã được phân chia đúng cách."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Hiển thị một số hình ảnh từ tập train\n",
    "train_dir = os.path.join(output_dir, 'train')\n",
    "class_names = os.listdir(train_dir)\n",
    "print(f'Classes: {class_names}')\n",
    "\n",
    "# Chọn ngẫu nhiên một lớp\n",
    "random_class = random.choice(class_names)\n",
    "print(f'Random class: {random_class}')\n",
    "\n",
    "# Chọn ngẫu nhiên một hình ảnh từ lớp đó\n",
    "random_image_path = os.path.join(train_dir, random_class, random.choice(os.listdir(os.path.join(train_dir, random_class))))\n",
    "print(f'Random image path: {random_image_path}')\n",
    "\n",
    "# Hiển thị hình ảnh\n",
    "image = Image.open(random_image_path)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 8: Thực hiện tăng cường dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "# Định nghĩa các phép tăng cường dữ liệu\n",
    "augmentations = A.Compose([\n",
    "    A.RandomRotate90(),\n",
    "    A.Flip(),\n",
    "    A.Transpose(),\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(),\n",
    "        A.MultiplicativeNoise()\n",
    "    ], p=0.2),\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(p=0.2),\n",
    "        A.MedianBlur(blur_limit=3, p=0.1),\n",
    "        A.Blur(blur_limit=3, p=0.1),\n",
    "    ], p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=20, p=0.2),\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(p=0.3),\n",
    "        A.GridDistortion(p=0.1),\n",
    "        A.PiecewiseAffine(p=0.3),\n",
    "    ], p=0.2),\n",
    "    A.OneOf([\n",
    "        A.CLAHE(clip_limit=2),\n",
    "        A.Sharpen(),\n",
    "        A.Emboss(),\n",
    "        A.RandomBrightnessContrast(),\n",
    "    ], p=0.3),\n",
    "    A.HueSaturationValue(p=0.3),\n",
    "])\n",
    "\n",
    "# Tạo thư mục đầu ra cho dữ liệu tăng cường\n",
    "augmented_dir = os.path.join(home_dir, 'data/augmented')\n",
    "if not os.path.exists(augmented_dir):\n",
    "    os.makedirs(augmented_dir)\n",
    "\n",
    "# Áp dụng tăng cường dữ liệu\n",
    "for class_name in class_names:\n",
    "    class_dir = os.path.join(train_dir, class_name)\n",
    "    augmented_class_dir = os.path.join(augmented_dir, class_name)\n",
    "    if not os.path.exists(augmented_class_dir):\n",
    "        os.makedirs(augmented_class_dir)\n",
    "    for img_name in tqdm(os.listdir(class_dir)):\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        augmented = augmentations(image=image)\n",
    "        augmented_image = augmented['image']\n",
    "        augmented_image = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
    "        augmented_img_name = f'aug_{img_name}'\n",
    "        cv2.imwrite(os.path.join(augmented_class_dir, augmented_img_name), augmented_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 9: Xây dựng các hàm hỗ trợ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Define common hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Define common loss function and optimizer\n",
    "loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Define image size and input shape\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "input_shape = (img_height, img_width, 3)\n",
    "\n",
    "date_time = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "def get_model_save_path(model_name, augmented=False):\n",
    "    suffix = 'Aug' if augmented else 'Ori'\n",
    "    model_name_with_suffix = f\"{model_name}{suffix}\"\n",
    "    \n",
    "    if platform.system() == 'Linux':\n",
    "        base_path = f'/content/drive/MyDrive/ClassificationofMangoDiseases/models/{model_name_with_suffix}/{date_time}'\n",
    "    elif platform.system() == 'Windows':\n",
    "        base_path = f'D:\\\\Projects\\\\ClassificationofMangoDiseases\\\\models\\\\{model_name_with_suffix}\\\\{date_time}'\n",
    "    else:\n",
    "        raise ValueError('Unsupported platform')\n",
    "    \n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "    \n",
    "    return base_path\n",
    "\n",
    "def create_optimizer():\n",
    "    return tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "def plot_history(history, base_path):\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig(os.path.join(base_path, 'accuracy.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.savefig(os.path.join(base_path, 'loss.png'))\n",
    "    plt.close()\n",
    "\n",
    "def save_classification_report(y_true, y_pred, class_names, results_path):\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    df.to_csv(os.path.join(results_path, 'classification_report.csv'), index=True)\n",
    "\n",
    "def save_confusion_matrix(y_true, y_pred, class_names, results_path):\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(os.path.join(results_path, 'confusion_matrix.png'))\n",
    "    plt.close()\n",
    "\n",
    "def save_roc_curve(y_true, y_score, results_path, num_classes):\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    # Binarize the output\n",
    "    y_true_binarized = label_binarize(y_true, classes=[i for i in range(num_classes)])\n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot ROC curve for each class\n",
    "    plt.figure()\n",
    "    for i in range(num_classes):\n",
    "        plt.plot(fpr[i], tpr[i], lw=2, label='Class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(results_path, 'roc_curve.png'))\n",
    "    plt.close()\n",
    "\n",
    "def save_precision_recall_curve(y_true, y_score, results_path, num_classes):\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    y_true_binarized = label_binarize(y_true, classes=[i for i in range(num_classes)])\n",
    "    \n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    for i in range(num_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_true_binarized[:, i], y_score[:, i])\n",
    "\n",
    "    # Plot Precision-Recall curve for each class\n",
    "    plt.figure()\n",
    "    for i in range(num_classes):\n",
    "        plt.plot(recall[i], precision[i], lw=2, label='Class {0}'.format(i))\n",
    "    \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.savefig(os.path.join(results_path, 'precision_recall_curve.png'))\n",
    "    plt.close()\n",
    "\n",
    "def evaluate_model(model, valid_generator, class_names, base_path, results_path):\n",
    "    y_true = valid_generator.classes\n",
    "    y_pred = model.predict(valid_generator)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    save_classification_report(y_true, y_pred_classes, class_names, results_path)\n",
    "    save_confusion_matrix(y_true, y_pred_classes, class_names, results_path)\n",
    "    save_roc_curve(y_true, y_pred, results_path, num_classes=len(class_names))\n",
    "    save_precision_recall_curve(y_true, y_pred, results_path, num_classes=len(class_names))\n",
    "\n",
    "# Training data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'train'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    os.path.join(output_dir, 'val'),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "# Evaluate on original and augmented datasets\n",
    "def train_and_evaluate(models, train_generator, valid_generator, class_names, augmented=False):\n",
    "    for model_name, model in models.items():\n",
    "        model.compile(optimizer=create_optimizer(), loss=loss_function, metrics=['accuracy'])\n",
    "        base_path = get_model_save_path(model_name, augmented)\n",
    "        history = model.fit(train_generator, validation_data=valid_generator, epochs=epochs)\n",
    "        model.save(os.path.join(base_path, 'model.h5'))\n",
    "        plot_history(history, base_path)\n",
    "        \n",
    "        # Evaluate on test sets\n",
    "        results1_path = os.path.join(base_path, 'results1')\n",
    "        results2_path = os.path.join(base_path, 'results2')\n",
    "        evaluate_model(model, valid_generator, class_names, base_path, results1_path)\n",
    "        evaluate_model(model, valid_generator, class_names, base_path, results2_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 10: Định nghĩa và huấn luyện các mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mô hình 1: CNN Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "cnn_model = create_cnn_model(input_shape, num_classes)\n",
    "original_models = {\n",
    "    'CNNCustomOri': cnn_model\n",
    "}\n",
    "train_and_evaluate(original_models, train_generator, valid_generator, class_names, augmented=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mô hình 2: ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_resnet_model(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.ResNet50(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "resnet_model = create_resnet_model(input_shape, num_classes)\n",
    "original_models = {\n",
    "    'ResNet50Ori': resnet_model\n",
    "}\n",
    "train_and_evaluate(original_models, train_generator, valid_generator, class_names, augmented=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mô hình 3: InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inception_model(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.InceptionV3(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "inception_model = create_inception_model(input_shape, num_classes)\n",
    "original_models = {\n",
    "    'InceptionV3Ori': inception_model\n",
    "}\n",
    "train_and_evaluate(original_models, train_generator, valid_generator, class_names, augmented=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mô hình 4: DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_densenet_model(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.DenseNet121(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "densenet_model = create_densenet_model(input_shape, num_classes)\n",
    "original_models = {\n",
    "    'DenseNet121Ori': densenet_model\n",
    "}\n",
    "train_and_evaluate(original_models, train_generator, valid_generator, class_names, augmented=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mô hình 5: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_learning_model(input_shape, num_classes):\n",
    "    base_model = tf.keras.applications.VGG16(\n",
    "        input_shape=input_shape,\n",
    "        include_top=False,\n",
    "        weights='imagenet'\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "transfer_learning_model = create_transfer_learning_model(input_shape, num_classes)\n",
    "original_models = {\n",
    "    'VGG16Ori': transfer_learning_model\n",
    "}\n",
    "train_and_evaluate(original_models, train_generator, valid_generator, class_names, augmented=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mô hình 6: Augmented CNN Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_aug = create_cnn_model(input_shape, num_classes)\n",
    "augmented_models = {\n",
    "    'CNNCustomAug': cnn_model_aug\n",
    "}\n",
    "\n",
    "augmented_train_dir = os.path.join(home_dir, 'data/augmented')\n",
    "train_generator_aug = train_datagen.flow_from_directory(\n",
    "    augmented_train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "\n",
    "train_and_evaluate(augmented_models, train_generator_aug, valid_generator, class_names, augmented=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mô hình 7: Augmented ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model_aug = create_resnet_model(input_shape, num_classes)\n",
    "augmented_models = {\n",
    "    'ResNet50Aug': resnet_model_aug\n",
    "}\n",
    "\n",
    "train_and_evaluate(augmented_models, train_generator_aug, valid_generator, class_names, augmented=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mô hình 8: Augmented InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception_model_aug = create_inception_model(input_shape, num_classes)\n",
    "augmented_models = {\n",
    "    'InceptionV3Aug': inception_model_aug\n",
    "}\n",
    "\n",
    "train_and_evaluate(augmented_models, train_generator_aug, valid_generator, class_names, augmented=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mô hình 9: Augmented DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model_aug = create_densenet_model(input_shape, num_classes)\n",
    "augmented_models = {\n",
    "    'DenseNet121Aug': densenet_model_aug\n",
    "}\n",
    "\n",
    "train_and_evaluate(augmented_models, train_generator_aug, valid_generator, class_names, augmented=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mô hình 10: Augmented VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_learning_model_aug = create_transfer_learning_model(input_shape, num_classes)\n",
    "augmented_models = {\n",
    "    'VGG16Aug': transfer_learning_model_aug\n",
    "}\n",
    "\n",
    "train_and_evaluate(augmented_models, train_generator_aug, valid_generator, class_names, augmented=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Đánh giá và so sánh các mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models, valid_generator, class_names, results_path):\n",
    "    if not os.path.exists(results_path):\n",
    "        os.makedirs(results_path)\n",
    "    results = {}\n",
    "    for model_name, model in models.items():\n",
    "        base_path = get_model_save_path(model_name)\n",
    "        model = tf.keras.models.load_model(os.path.join(base_path, 'model.h5'))\n",
    "        y_true = valid_generator.classes\n",
    "        y_pred = model.predict(valid_generator)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        report = classification_report(y_true, y_pred_classes, target_names=class_names, output_dict=True)\n",
    "        results[model_name] = report['accuracy']\n",
    "        \n",
    "    results_df = pd.DataFrame.from_dict(results, orient='index', columns=['accuracy'])\n",
    "    results_df.to_csv(os.path.join(results_path, 'model_comparison.csv'))\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.barplot(x=results_df.index, y=results_df['accuracy'])\n",
    "    plt.xlabel('Model')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model Comparison')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.savefig(os.path.join(results_path, 'model_comparison.png'))\n",
    "    plt.close()\n",
    "\n",
    "all_models = {\n",
    "    'CNNCustomOri': cnn_model,\n",
    "    'ResNet50Ori': resnet_model,\n",
    "    'InceptionV3Ori': inception_model,\n",
    "    'DenseNet121Ori': densenet_model,\n",
    "    'VGG16Ori': transfer_learning_model,\n",
    "    'CNNCustomAug': cnn_model_aug,\n",
    "    'ResNet50Aug': resnet_model_aug,\n",
    "    'InceptionV3Aug': inception_model_aug,\n",
    "    'DenseNet121Aug': densenet_model_aug,\n",
    "    'VGG16Aug': transfer_learning_model_aug\n",
    "}\n",
    "\n",
    "compare_models(all_models, valid_generator, class_names, os.path.join(home_dir, 'model_comparison'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_single_model(model_name, model, train_generator, valid_generator, class_names, augmented=False):\n",
    "    model.compile(optimizer=create_optimizer(), loss=loss_function, metrics=['accuracy'])\n",
    "    base_path = get_model_save_path(model_name, augmented)\n",
    "    history = model.fit(train_generator, validation_data=valid_generator, epochs=epochs)\n",
    "    model.save(os.path.join(base_path, 'model.h5'))\n",
    "    plot_history(history, base_path)\n",
    "    \n",
    "    # Evaluate on test sets\n",
    "    results1_path = os.path.join(base_path, 'results1')\n",
    "    results2_path = os.path.join(base_path, 'results2')\n",
    "    evaluate_model(model, valid_generator, class_names, base_path, results1_path)\n",
    "    evaluate_model(model, valid_generator, class_names, base_path, results2_path)\n",
    "\n",
    "cnn_model = create_cnn_model(input_shape, num_classes)\n",
    "train_and_evaluate_single_model('CNNCustomOri', cnn_model, train_generator, valid_generator, class_names, augmented=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
